{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import dummy, metrics, linear_model, model_selection, neighbors\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introdução ao Aprendizado de Máquina"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trabalhando com dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregando os datasets\n",
    "\n",
    "Nós iremos ver duas vertentes do mesmo dataset, com propósitos diferentes. `Weather` é um dataset educacional (composto por dados fictícios) amplamente usado para ensinar conceitos de aprendizado de máquina. Ele contém 14 instâncias, 4 features e é considerado um dataset de classificação binária."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_nominal = pd.read_csv('./weather.nominal.csv')\n",
    "weather_nominal\n",
    "\n",
    "weather_numeric = pd.read_csv('./weather.csv')\n",
    "weather_numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui vamos conferir os possíveis valores únicos em colunas categóricas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Outlook:', weather_nominal.outlook.unique())\n",
    "print('Temperature:', weather_nominal.temperature.unique())\n",
    "print('Humidity:', weather_nominal.humidity.unique())\n",
    "print('Windy:', weather_nominal.windy.unique())\n",
    "print('Play:', weather_nominal.play.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostrando dataset com `head` (5 primeiros valores) e `tail` (5 últimos valores), bom para datasets extensos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_nominal.head()\n",
    "weather_numeric.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformando os dados categóricos em numéricos\n",
    "\n",
    "Para usar os datasets, nós devemos transformar os dados categóricos em valores numéricos, já que tanto nosso método de classificação quanto o de regressão trabalham apenas com números. Iremos usar uma técnica de encoding básica, mapeando os valores categóricos para números.\n",
    "\n",
    "Uma forma mais \"profissional\" de fazer a transformação de dados é o `One-hot encoding`, mas não será tratado aqui."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mudando o tipo das colunas categóricas\n",
    "weather_numeric['outlook'] = weather_numeric['outlook'].astype('category')\n",
    "weather_numeric['windy'] = weather_numeric['windy'].astype('category')\n",
    "weather_numeric['play'] = weather_numeric['play'].astype('category')\n",
    "\n",
    "# Aplicando enconding às colunas selecionadas\n",
    "cat_columns = weather_numeric.select_dtypes(['category']).columns\n",
    "weather_numeric[cat_columns] = weather_numeric[cat_columns].apply(lambda x: x.cat.codes)\n",
    "weather_numeric.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividindo datasets em treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_nominal_train, X_nominal_test, y_nominal_train, y_nominal_test = train_test_split(\n",
    "    weather_nominal.iloc[:, :-1], \n",
    "    weather_nominal.iloc[:, -1], \n",
    "    test_size=0.3\n",
    ")\n",
    "\n",
    "X_nominal_train\n",
    "X_nominal_test\n",
    "y_nominal_train\n",
    "y_nominal_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_numeric_train, X_numeric_test, y_numeric_train, y_numeric_test = train_test_split(\n",
    "    weather_numeric.iloc[:, :-1], \n",
    "    weather_numeric.iloc[:, -1], \n",
    "    test_size=0.3\n",
    ")\n",
    "\n",
    "X_numeric_train\n",
    "X_numeric_test\n",
    "y_numeric_train\n",
    "y_numeric_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classificação\n",
    "\n",
    "Vamos usar o KNN para classificar as instâncias do `Weather`. Como funciona o KNN? Imagine que suas instâncias estão distribuídas pelo espaço (então você tem a ideia de pontos e o conceito de distâncias) e que instâncias próximas são semelhantes. Logo, você pode \"adivinhar\" a classe de uma instância olhando para seus vizinhos.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification = neighbors.KNeighborsClassifier(n_neighbors=3)\n",
    "classification.fit(X_numeric_train, y_numeric_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_predict = classification.predict(X_numeric_test)\n",
    "class_predict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressão\n",
    "\n",
    "Vamos agora usar a Regressão Linear para fazer a regressão das instâncias do `Weather`. A ideia da regressão linear é explicar seus dados como uma função `y = a * x + b + e`, onde `a` e `b` são coeficientes e `e` é um termo de erro, ou seja, uma medida que mostra que existem outros fatores não explicados pelo modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression = linear_model.LinearRegression()\n",
    "regression.fit(X_numeric_train, y_numeric_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr_predict = regression.predict(X_numeric_test)\n",
    "regr_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avaliação de resultados\n",
    "\n",
    "Existem várias formas de medir quão \"bom\" é um modelo (apesar de isso ser subjetivo), as métricas são boas formas. Elas testam resultados gerados pelos modelos com valores reais, e dão uma ideia de quão preciso é o seu modelo na classificação (ou quão bem sua curva explica os dados na regressão)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('KNN:')\n",
    "print(metrics.classification_report(y_numeric_test, class_predict))\n",
    "\n",
    "print('Regressão:')\n",
    "print(metrics.mean_squared_error(y_numeric_test, regr_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation\n",
    "\n",
    "A ideia é evitar o overfitting fazendo passos intermediários de validação com uma parte do dataset de treino. Por exemplo, uma validação cruzada de 10 folds treina o modelo com 9 pedaços e valida os resultados obtidos com o pedaço restante, e repete esse processo mais 9 vezes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('KNN:')\n",
    "print('validação cruzada:', model_selection.cross_validate(\n",
    "    classification, \n",
    "    X_numeric_train, \n",
    "    y_numeric_train,\n",
    "    cv=2\n",
    "))\n",
    "\n",
    "print('Regressão:')\n",
    "print('validação cruzada:', model_selection.cross_validate(\n",
    "    regression, \n",
    "    X_numeric_train, \n",
    "    y_numeric_train,\n",
    "    cv=2\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline classifier\n",
    "\n",
    "É muito difícil avaliar o resultado de um modelo (descobrir se o valor resultante das métricas é bom ou não), mas existe uma forma de descobrir qual seria o pior valor possível. A ideia é usar um classificador \"dummy\", isto é, uma estratégia ingênua de classificação. Neste caso apresentado abaixo, o dummy checa qual a classe dominante e classifica as instâncias de teste com aquela mesma classe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification = dummy.DummyClassifier(strategy='most_frequent')\n",
    "classification.fit(X_nominal_train, y_nominal_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = classification.predict(X_nominal_test)\n",
    "\n",
    "metrics.accuracy_score(y_nominal_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
